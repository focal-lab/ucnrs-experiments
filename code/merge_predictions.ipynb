{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scientific_python_utils.geospatial import ensure_projected_CRS\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEOSPATIAL_MAPS_FOLDER = Path(\"/ofo-share/scratch-david/NRS-all-sites/geospatial_maps\")\n",
    "SHIFT_PER_DATASET = \"/ofo-share/repos-david/UCNRS-experiments/data/shift_per_dataset.json\"\n",
    "METADATA_FILE = \"/ofo-share/drone-imagery-organization/3c_metadata-extracted/all-mission-polygons-w-metadata.gpkg\"\n",
    "OUTPUT_FILE = \"/ofo-share/repos-david/UCNRS-experiments/data/all_geospatial_maps_merged.geojson\"\n",
    "\n",
    "# Simplify the geometry such that the maximum deviation never exceeds this amount\n",
    "SIMPLIFY_TOL = 0.1\n",
    "BUFFER_AMOUNT = -0.01\n",
    "VIS = True\n",
    "\n",
    "# Allows you to specify a subset of the data for testing\n",
    "START_IND = 0\n",
    "STOP_IND = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missions_metadata = gpd.read_file(METADATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "# List all the files that are present\n",
    "map_files = sorted(GEOSPATIAL_MAPS_FOLDER.glob(\"*\"))[START_IND:STOP_IND]\n",
    "\n",
    "# Open the list of shifts for each dataset\n",
    "with open(SHIFT_PER_DATASET, \"r\") as infile:\n",
    "    shifts_per_dataset = json.load(infile)\n",
    "\n",
    "# Iterate over all datasets. Read them and post-process the results\n",
    "all_dataframes = []\n",
    "for map_file in map_files:\n",
    "    mission_id = map_file.stem\n",
    "\n",
    "    if mission_id not in shifts_per_dataset:\n",
    "        print(f\"Mission ID {mission_id} not in shifts_per_dataset. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Try to read the dataset from disk\n",
    "    print(f\"Reading {map_file}\")\n",
    "    try:\n",
    "        gdf = gpd.read_file(map_file)\n",
    "    except:\n",
    "        print(f\"Failed to read {mission_id}. Skipping\")\n",
    "        continue\n",
    "\n",
    "    # Make sure this is in a projected CRS so geometric operations work as expected\n",
    "    gdf = ensure_projected_CRS(gdf)\n",
    "    # Simplify the geometry to make future operations faster\n",
    "    print(\"Simplifying \")\n",
    "    gdf.geometry = gdf.simplify(SIMPLIFY_TOL)\n",
    "    # Make sure the geometry is valid. This is especially important because this data is generated\n",
    "    # from the projection of the mesh.\n",
    "    #gdf.geometry = gdf.make_valid()\n",
    "    print(\"Buffering\")\n",
    "    gdf.geometry = gdf.buffer(BUFFER_AMOUNT)\n",
    "    # Add a dataset identifier\n",
    "    gdf[\"mission_id\"] = mission_id\n",
    "\n",
    "    # Extract the corresponding mission-level metadata which contains the bounding flight polygon\n",
    "    metadata_for_mission = missions_metadata[missions_metadata.mission_id == mission_id]\n",
    "    # Make the CRS for the flight polygon match that of the prediction\n",
    "    metadata_for_mission.to_crs(gdf.crs, inplace=True)\n",
    "    # Extract the actual polygon element\n",
    "    mission_polygon = metadata_for_mission.geometry.values[0]\n",
    "\n",
    "    print(\"before clip\")\n",
    "    print(gdf.geometry)\n",
    "    # Clip the prediction to the extent of the mission polygon\n",
    "    gdf = gpd.clip(gdf=gdf, mask=mission_polygon, keep_geom_type=True)\n",
    "    # Undo the buffering ammount that was done initially\n",
    "    gdf.geometry = gdf.buffer(-BUFFER_AMOUNT)\n",
    "    print(\"After clip\")\n",
    "    print(gdf.geometry)\n",
    "\n",
    "    # Get the x, y shift for this dataset\n",
    "    shift = shifts_per_dataset[mission_id]\n",
    "    # Apply this shift. Note it's important this happens after the crop occurs since the flight\n",
    "    # polygon is relative to the input data, not absolute.\n",
    "    gdf.geometry = gdf.translate(xoff=shift[0], yoff=shift[1])\n",
    "\n",
    "    # Visualize if requested\n",
    "    if VIS:\n",
    "        f, ax = plt.subplots()\n",
    "        metadata_for_mission.boundary.plot(ax=ax)\n",
    "        gdf.plot(\"class_names\", legend=True, vmin=-0.5, vmax=9.5, ax=ax)\n",
    "        plt.show()\n",
    "\n",
    "    all_dataframes.append(gdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataframes = pd.concat(all_dataframes)\n",
    "print(merged_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataframes.to_file(OUTPUT_FILE)\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDRT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
